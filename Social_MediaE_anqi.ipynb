{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "%pylab inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace related words to \"Aspiration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aim': 'aspiration',\n",
       " 'ambition': 'aspiration',\n",
       " 'desire': 'aspiration',\n",
       " 'dream': 'aspiration',\n",
       " 'eager': 'aspiration',\n",
       " 'goal': 'aspiration',\n",
       " 'hope': 'aspiration',\n",
       " 'ideal': 'aspiration',\n",
       " 'love': 'aspiration',\n",
       " 'target': 'aspiration',\n",
       " 'want': 'aspiration',\n",
       " 'wish': 'aspiration'}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaceDict = pd.read_csv(\"/Users/anqihuang/Desktop/MSBASPRING/aspire_replace.csv\")\n",
    "replaceDict.columns = ['Replace', 'Search']\n",
    "replaceDict['Search'] = replaceDict['Search'].str.lower()\n",
    "replaceDict['Search'] = replaceDict['Search'].str.replace(\"\\xc2\\xa0\", \"\")\n",
    "\n",
    "replaceDict['Replace'] = replaceDict['Replace'].str.lower()\n",
    "attribute = replaceDict['Replace'].unique().tolist()\n",
    "        \n",
    "replaceDict = replaceDict.set_index('Search').to_dict()\n",
    "replaceDict = replaceDict['Replace']\n",
    "replaceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pd.read_csv(\"/Users/anqihuang/Desktop/MSBASPRING/brand_name.csv\")\n",
    "model.columns = ['Model','Replacement']\n",
    "\n",
    "brands = model['Model'].unique().tolist()\n",
    "aspiration = ['dream', 'goal', 'target', 'hope','aim','ideal','ambition', 'desire','wish','want','eager','love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i understand it's not about the speed.  i really don't care if the car won't do over 100 as i rarely break the toyota mark.  what i do care about is power and with the manual mode on the auto, i can get it when i want it.  will i buy an auto-equipped g?  in all likelihood, no.  i desperately want to drive the 6 speed.\""
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dictReplace(x):\n",
    "    for i,j in replaceDict.items():\n",
    "        my_regex = r\"\\s\" + re.escape(i) + r\"\\b\"\n",
    "        if re.search(my_regex, x, re.IGNORECASE):\n",
    "            x = x.replace(i,j)\n",
    "    return x\n",
    "\n",
    "edmunds = pd.read_csv(\"/Users/anqihuang/Desktop/MSBASPRING/after_mapping3.csv\",sep=\"\\t\",skiprows=[0],encoding='utf-8',header=None)\n",
    "\n",
    "\n",
    "edmunds.columns=['date','user','text']\n",
    "edmunds['text'] = edmunds['text'].str.lower()\n",
    "edmunds.text.ix[3].encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i understand it's not about the speed.  i really don't care if the car won't do over 100 as i rarely break the toyota mark.  what i do care about is power and with the manual mode on the auto, i can get it when i aspiration it.  will i buy an auto-equipped g?  in all likelihood, no.  i desperately aspiration to drive the 6 speed.\""
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edmunds['text'] = edmunds['text'].map(dictReplace)\n",
    "edmunds.text.ix[3].encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most 100 frequent appeareds word in all comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "jobdes_cleaned = []\n",
    "jobdes_lemmatized = []\n",
    "jobdes_nostopwords = []\n",
    "\n",
    "# remove it if you need punctuation\n",
    "stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','****','...','``']) \n",
    "comment2 = edmunds[\"text\"].tolist()\n",
    "comment = \"\".join(comment2)\n",
    "word_tokenize = nltk.word_tokenize(comment)\n",
    "lemma_word = map(lambda x: lemmatizer.lemmatize(x), word_tokenize)\n",
    "jobdes_lemmatized.append(lemma_word)\n",
    "no_stop = filter(lambda x: x not in stop_words, word_tokenize)\n",
    "jobdes_nostopwords.append(no_stop)\n",
    "cleaned_text = filter(lambda x: x not in stop_words, lemma_word)\n",
    "jobdes_cleaned.append(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car;6558\n",
      "bmw;4313\n",
      "'s;4279\n",
      "n't;3910\n",
      "wa;3313\n",
      "acura;3131\n",
      "'';2556\n",
      "like;2158\n",
      "would;2128\n",
      "one;2040\n",
      "infiniti;1999\n",
      "$;1989\n",
      "ha;1971\n",
      "audi;1871\n",
      "get;1790\n",
      "-;1720\n",
      "aspiration;1518\n",
      "think;1479\n",
      "drive;1347\n",
      "new;1295\n",
      "&;1246\n",
      "year;1231\n",
      "better;1197\n",
      "much;1163\n",
      "doe;1152\n",
      "lexus;1134\n",
      "'m;1093\n",
      "even;1071\n",
      "good;1064\n",
      "make;1024\n",
      "sedan;1012\n",
      "also;971\n",
      "driving;962\n",
      "really;945\n",
      "look;934\n",
      "price;933\n",
      "time;932\n",
      "know;919\n",
      "well;917\n",
      "performance;913\n",
      "mercedes;913\n",
      "people;903\n",
      "luxury;867\n",
      "cadillac;860\n",
      "say;825\n",
      "interior;806\n",
      "sport;784\n",
      "could;773\n",
      "engine;772\n",
      "honda;769\n",
      "'ve;764\n",
      "go;753\n",
      "still;732\n",
      "see;720\n",
      "#;716\n",
      "test;709\n",
      "thing;702\n",
      "great;697\n",
      "vehicle;689\n",
      "back;688\n",
      "lot;683\n",
      "way;672\n",
      "buy;654\n",
      "manual;634\n",
      "feel;628\n",
      "seat;617\n",
      "need;615\n",
      "many;609\n",
      "model;598\n",
      "rwd;595\n",
      "best;595\n",
      "going;587\n",
      "3;585\n",
      "awd;580\n",
      "--;571\n",
      "mile;568\n",
      "take;565\n",
      "'d;556\n",
      "may;555\n",
      "toyota;555\n",
      "problem;543\n",
      "point;536\n",
      "dealer;530\n",
      "le;528\n",
      "'ll;526\n",
      "looking;524\n",
      "tire;524\n",
      "come;521\n",
      "right;516\n",
      "handling;513\n",
      "%;510\n",
      "cost;508\n",
      "since;507\n",
      "said;505\n",
      "never;500\n",
      "road;500\n",
      "got;497\n",
      "'re;492\n",
      "power;485\n",
      "nissan;479\n",
      "fwd;475\n",
      "nice;471\n",
      "sure;468\n",
      "driver;466\n",
      "probably;459\n",
      "jaguar;457\n",
      "two;450\n",
      "drove;448\n",
      "ca;443\n",
      "something;441\n",
      "wheel;439\n",
      "around;439\n",
      "option;432\n",
      "first;430\n",
      "last;421\n",
      "2;420\n",
      "every;411\n",
      "different;408\n",
      "day;405\n",
      "find;399\n",
      "volvo;395\n",
      "sale;392\n",
      "difference;385\n",
      "getting;383\n",
      "hp;380\n",
      "though;379\n",
      "little;378\n",
      "g;377\n",
      "package;377\n",
      "speed;372\n",
      "opinion;369\n",
      "used;368\n",
      "auto;368\n",
      "u;367\n",
      "coupe;367\n",
      "agree;366\n",
      "transmission;366\n",
      "post;363\n",
      "issue;361\n",
      "brand;361\n",
      "330i;360\n",
      "pretty;358\n",
      "far;358\n",
      "another;354\n",
      "experience;353\n",
      "value;353\n",
      "maybe;350\n",
      "class;350\n",
      "old;350\n",
      "seems;347\n",
      "bought;345\n",
      "thought;345\n",
      "big;345\n",
      "mean;344\n",
      "fun;343\n",
      "might;343\n",
      "automatic;343\n",
      "long;341\n",
      "bad;340\n",
      "bit;340\n",
      "actually;338\n",
      "front;337\n",
      "month;336\n",
      "least;336\n",
      "reliability;335\n",
      "made;335\n",
      "always;329\n",
      "fact;328\n",
      "driven;328\n",
      "torque;325\n",
      "money;325\n",
      "put;324\n",
      "almost;322\n",
      "ride;321\n",
      "lease;320\n",
      "quality;316\n",
      "next;315\n",
      "without;314\n",
      "system;313\n",
      "line;310\n",
      "etc;310\n",
      "give;308\n",
      "reason;306\n",
      "believe;305\n",
      "choice;303\n",
      "high;302\n",
      "6;301\n",
      "volkswagen;301\n",
      "level;300\n",
      "enough;299\n",
      "top;298\n",
      "read;295\n",
      "however;294\n",
      "keep;291\n",
      "4;291\n",
      "either;291\n",
      "number;290\n",
      "snow;290\n",
      "quite;289\n",
      "guess;288\n",
      "part;287\n",
      "others;284\n",
      "5;284\n",
      "anyone;282\n",
      "work;282\n",
      "wife;281\n",
      "ever;278\n",
      "use;277\n",
      "nothing;277\n",
      "change;276\n",
      "end;276\n",
      "rear;274\n",
      "hard;273\n",
      "real;268\n",
      "small;266\n",
      "deal;266\n",
      "feature;266\n",
      "let;264\n",
      "ford;264\n",
      "based;264\n",
      "owner;263\n",
      "steering;263\n",
      "else;261\n",
      "second;261\n",
      "offer;260\n",
      "146;253\n",
      "gas;252\n",
      "yet;248\n",
      "forum;247\n",
      "market;247\n",
      "pay;246\n",
      "tell;245\n",
      "size;243\n",
      "course;242\n",
      "comparison;240\n",
      "list;238\n",
      "buying;238\n",
      "anything;237\n",
      "fast;235\n",
      "compared;233\n",
      "leather;232\n",
      "entry;231\n",
      "guy;230\n",
      "subaru;230\n",
      "standard;229\n",
      "warranty;229\n",
      "current;228\n",
      "care;228\n",
      "mpg;225\n",
      "german;225\n",
      "review;225\n",
      "someone;224\n",
      "close;223\n",
      "discussion;222\n",
      "mileage;222\n",
      "seem;222\n",
      "hyundai;221\n",
      "sound;221\n",
      "mph;221\n",
      "brake;219\n",
      "1;218\n",
      "yes;215\n",
      "base;214\n",
      "saab;214\n",
      "mazda;213\n",
      "true;212\n",
      "side;211\n",
      "consider;211\n",
      "v6;209\n",
      "control;209\n",
      "service;208\n",
      "sell;208\n",
      "owned;207\n",
      "trying;207\n",
      "available;206\n",
      "fit;205\n",
      "low;205\n",
      "everything;205\n",
      "sold;202\n",
      "buyer;201\n",
      "japanese;201\n",
      "went;201\n",
      "styling;201\n",
      "especially;200\n",
      "live;199\n",
      "ago;198\n",
      "suspension;197\n",
      "design;197\n",
      "found;197\n",
      "try;197\n",
      "handle;196\n",
      "track;196\n",
      "start;195\n",
      "factor;195\n",
      "worth;194\n",
      "near;194\n",
      "came;192\n",
      "everyone;190\n",
      "extra;189\n",
      "version;188\n"
     ]
    }
   ],
   "source": [
    "whole_list = jobdes_cleaned[0]\n",
    "jobdes_bow_cleaned_freq = nltk.FreqDist(whole_list)\n",
    "for word, frequency in jobdes_bow_cleaned_freq.most_common(300):\n",
    "    print('%s;%d' % (word, frequency)).encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a 2-D array to store time of terms co-occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "c = defaultdict(dict)\n",
    "# make a copy dictionary to handle the case of term pair only count once for each post \n",
    "copy = defaultdict(dict)\n",
    "\n",
    "# insert default value 0 into array\n",
    "for i in brands:\n",
    "   \n",
    "    c[i] = 0\n",
    "# insert default value 0 into array\n",
    "for z in brands:\n",
    "    \n",
    "    copy[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "filter_word = set(list(string.punctuation) + stopwords.words('english'))\n",
    "\n",
    "def tokenizer(s):\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    cleanup = [token.lower() for token in tokens if token not in filter_word]\n",
    "    return cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total count of brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'toyata': 0, 'seat': 222, 'subaru': 143, 'buick': 85, 'lexus': 639, 'audi': 747, 'mercury': 5, 'saturn': 7, 'chevrolet': 118, 'suzuki': 20, 'volkswagen': 187, 'dodge': 47, 'pontiac': 58, 'cadillac': 407, 'honda': 489, 'hyundai': 130, 'ford': 183, 'mazda': 124, 'hyundai.': 1, 'infiniti': 1019, 'bmw': 1865, 'hyndai kia': 0, 'sedan': 578, 'kia': 18, 'mitsubishi': 21, 'problem': 240, 'lincoln': 81, 'acura': 1272, 'jaguar': 129, 'nissan': 256, 'toyota': 375, 'volvo': 203, 'chrysler': 72, 'mercedes': 501, 'hyundai,': 0}\n"
     ]
    }
   ],
   "source": [
    "brand_count = {}\n",
    "for brand in brands:\n",
    "    brand_count[brand] = 0\n",
    "\n",
    "for sentence in comment2:\n",
    "    sentence=sentence.strip()\n",
    "    tokens=[token for token in tokenizer(sentence) if token!=u\"\"]\n",
    "    for brand in brands:\n",
    "        if brand in tokens:\n",
    "            brand_count[brand] += 1  \n",
    "print brand_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  the total count of \"Aspiration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074\n"
     ]
    }
   ],
   "source": [
    "aspir_count = 0\n",
    "\n",
    "for sentence in comment2:\n",
    "    sentence = sentence.strip()\n",
    "    tokens=[token for token in tokenizer(sentence) if token!=u\"\"]\n",
    "    if 'aspiration' in tokens:\n",
    "        aspir_count += 1\n",
    "print aspir_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'acura': 174,\n",
       "             'audi': 91,\n",
       "             'bmw': 260,\n",
       "             'buick': 5,\n",
       "             'cadillac': 54,\n",
       "             'chevrolet': 7,\n",
       "             'chrysler': 4,\n",
       "             'dodge': 2,\n",
       "             'ford': 14,\n",
       "             'honda': 48,\n",
       "             'hyndai kia': 0,\n",
       "             'hyundai': 7,\n",
       "             'hyundai,': 0,\n",
       "             'hyundai.': 0,\n",
       "             'infiniti': 131,\n",
       "             'jaguar': 14,\n",
       "             'kia': 2,\n",
       "             'lexus': 75,\n",
       "             'lincoln': 6,\n",
       "             'mazda': 12,\n",
       "             'mercedes': 52,\n",
       "             'mercury': 0,\n",
       "             'mitsubishi': 3,\n",
       "             'nissan': 23,\n",
       "             'pontiac': 5,\n",
       "             'problem': 22,\n",
       "             'saturn': 0,\n",
       "             'seat': 30,\n",
       "             'sedan': 63,\n",
       "             'subaru': 19,\n",
       "             'suzuki': 1,\n",
       "             'toyata': 0,\n",
       "             'toyota': 40,\n",
       "             'volkswagen': 17,\n",
       "             'volvo': 22})"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 10\n",
    "for sentence in comment2:\n",
    "    sentence=sentence.strip()\n",
    "    tokens=[token for token in tokenizer(sentence) if token!=u\"\"]\n",
    "    for pos,token in enumerate(tokens):\n",
    "        if token.lower() in brands:\n",
    "            start=max(0,pos-window_size)\n",
    "            end=min(len(tokens),pos+window_size+1) \n",
    "            for pos2 in xrange(start,end):\n",
    "                if pos2==pos: \n",
    "                    continue\n",
    "                aspire = tokens[pos2]\n",
    "                if 'aspiration'in aspire:\n",
    "                    if c[token] == copy[token]:\n",
    "                        c[token] = c[token] + 1\n",
    "                        \n",
    "           \n",
    "    copy = c.copy()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total count of comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5062\n"
     ]
    }
   ],
   "source": [
    "N = len(comment2)\n",
    "print N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acura 0.6447331436\n",
      "audi 0.574167557879\n",
      "bmw 0.657071107982\n",
      "buick 0.277248329499\n",
      "cadillac 0.625341440984\n",
      "chevrolet 0.279597891614\n",
      "chrysler 0.261845644527\n",
      "dodge 0.20056262134\n",
      "ford 0.360574330169\n",
      "honda 0.462647519165\n",
      "hyundai 0.253788855465\n",
      "hyundai. 0.0\n",
      "infiniti 0.60591955819\n",
      "kia 0.523691289054\n",
      "lincoln 0.349127526036\n",
      "mazda 0.456118219499\n",
      "mercedes 0.489196653248\n",
      "mercury 0.0\n",
      "mitsubishi 0.673317371641\n",
      "nissan 0.423453503259\n",
      "pontiac 0.406312207025\n",
      "problem 0.43204531347\n",
      "saturn 0.0\n",
      "seat 0.636921838039\n",
      "sedan 0.513724845837\n",
      "subaru 0.626232240757\n",
      "suzuki 0.235661080074\n",
      "toyota 0.502743637492\n",
      "volkswagen 0.428474691045\n",
      "volvo 0.510792488831\n",
      "lexus 0.553195023649\n",
      "jaguar 0.511512421867\n"
     ]
    }
   ],
   "source": [
    "lift = {}\n",
    "for i in brands:\n",
    "    if brand_count[i] != 0:\n",
    "        #print i, N, c[i], aspir_count, brand_count[i]\n",
    "        lift[i] = (N*c[i]*1.0)/(aspir_count*brand_count[i]*1.0)\n",
    "        print i,lift[i]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
